{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "def prune_tokens(input_ids, embeddings, merge_n=2):\n",
    "    input_ids = input_ids.to(embeddings.device)\n",
    "    merged_input_ids_list = []\n",
    "    merged_embeddings_list = []\n",
    "    # MERGE TOKEN N-WISE\n",
    "    for i in range(0, input_ids.shape[1] - merge_n + 1, merge_n):\n",
    "        merged_embedding = torch.mean(embeddings[:, i:i+merge_n], dim=1) # embeddings = [batch, seq_len, embed_dim]        \n",
    "        merged_token_id = input_ids[:, i]\n",
    "        merged_input_ids_list.append(merged_token_id)\n",
    "        merged_embeddings_list.append(merged_embedding)\n",
    "    \n",
    "    remaining_tokens = input_ids.shape[1] % merge_n\n",
    "    if remaining_tokens > 0:\n",
    "        start_idx = input_ids.shape[1] - remaining_tokens\n",
    "        if remaining_tokens == 1:\n",
    "            merged_input_ids_list.append(input_ids[:, -1])\n",
    "            merged_embeddings_list.append(embeddings[:, -1])\n",
    "        else:\n",
    "            merged_embedding = torch.mean(embeddings[:, start_idx:], dim=1)\n",
    "            merged_token_id = input_ids[:, start_idx]\n",
    "            merged_input_ids_list.append(merged_token_id)\n",
    "            merged_embeddings_list.append(merged_embedding)\n",
    "    \n",
    "    merged_input_ids = torch.stack(merged_input_ids_list, dim=1)\n",
    "    merged_embeddings = torch.stack(merged_embeddings_list, dim=1)\n",
    "    \n",
    "    return merged_input_ids, merged_embeddings\n",
    "\n",
    "def modify_bart_for_token_merging(model, input_ids, merge_n=2):\n",
    "    input_embeddings = model.get_input_embeddings()(input_ids) # SMALL NOTE: THIS FUNCTION DOES BOTH INPUT EMBEDDINGS + POSITIONAL EMBEDDINGS...\n",
    "    print(\"INPUT EMEBDGS SHAEP\")\n",
    "    print(input_embeddings.shape)\n",
    "    merged_input_ids, merged_embeddings = merge_tokens(input_ids, input_embeddings, merge_n) \n",
    "    return merged_input_ids\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\").to(device)    \n",
    "ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
    "test_dataset = ds['test']    \n",
    "merge_n_values = [2, 3, 4]\n",
    "for merge_n in merge_n_values:\n",
    "    print(f\"\\nToken Merging with merge_n = {merge_n}\")        \n",
    "    subset_size = 50\n",
    "    random_indices = random.sample(range(len(test_dataset)), subset_size)\n",
    "    test_dataset_subset = test_dataset.select(random_indices)\n",
    "    \n",
    "    rouge = evaluate.load('rouge')\n",
    "    bleu = evaluate.load('bleu')\n",
    "    \n",
    "    total_flops = 0\n",
    "    total_time = 0\n",
    "    outputs = []\n",
    "    targets = []        \n",
    "    original_sequence_lengths = []\n",
    "    merged_sequence_lengths = []\n",
    "    \n",
    "    for data in tqdm(test_dataset_subset):\n",
    "        article = data['article']\n",
    "        reference_summary = data['highlights']\n",
    "        \n",
    "        inputs = tokenizer(article, return_tensors='pt', max_length=1024, truncation=True).to(device)\n",
    "        \n",
    "        original_sequence_lengths.append(inputs['input_ids'].shape[1])            \n",
    "        merged_input_ids = modify_bart_for_token_merging(model, inputs['input_ids'], merge_n)            \n",
    "        merged_sequence_lengths.append(merged_input_ids.shape[1])\n",
    "        \n",
    "        flops_analysis = FlopCountAnalysis(model, merged_input_ids)\n",
    "        total_flops += flops_analysis.total()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        summary_ids = model.generate(merged_input_ids)\n",
    "        end_time = time.time()\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        generated_summary = tokenizer.decode(\n",
    "            summary_ids[0], \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        \n",
    "        total_time += (end_time - start_time)\n",
    "        outputs.append(generated_summary)\n",
    "        targets.append(reference_summary)\n",
    "    \n",
    "    average_flops = total_flops / len(test_dataset_subset)\n",
    "    average_time = total_time / len(test_dataset_subset)\n",
    "    \n",
    "    avg_original_length = sum(original_sequence_lengths) / len(original_sequence_lengths)\n",
    "    avg_merged_length = sum(merged_sequence_lengths) / len(merged_sequence_lengths)\n",
    "    length_reduction_percentage = ((avg_original_length - avg_merged_length) / avg_original_length) * 100\n",
    "    \n",
    "    rouge_results = rouge.compute(predictions=outputs, references=targets)\n",
    "    bleu_results = bleu.compute(predictions=outputs, references=targets)\n",
    "    \n",
    "    print(\"Inference Results:\")\n",
    "    print(f\"Average FLOPs: {average_flops:.2e}\")\n",
    "    print(f\"Average forward pass time: {average_time:.4f} seconds\")\n",
    "    print(f\"Average Original Sequence Length: {avg_original_length:.2f}\")\n",
    "    print(f\"Average Merged Sequence Length: {avg_merged_length:.2f}\")\n",
    "    print(f\"Sequence Length Reduction: {length_reduction_percentage:.2f}%\")\n",
    "    print(\"ROUGE Scores:\", rouge_results)\n",
    "    print(\"BLEU Score:\", bleu_results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
